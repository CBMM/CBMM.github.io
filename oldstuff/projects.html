<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2015-11-16 Mon 17:56 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>CBMM Projects</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Greg Hale" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css"/>
<link rel="stylesheet" type="text/css" href="projects.css"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">CBMM Projects</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline40">1. Development</a>
<ul>
<li><a href="#orgheadline16">1.1. Tagging</a>
<ul>
<li><a href="#orgheadline1">1.1.1. Stimulus annotation platform</a></li>
<li><a href="#orgheadline5">1.1.2. Types of stimuli:</a></li>
<li><a href="#orgheadline11">1.1.3. Types of annotations:</a></li>
<li><a href="#orgheadline15">1.1.4. Users</a></li>
</ul>
</li>
<li><a href="#orgheadline21">1.2. Center for Brains, Minds and Machines as as Service (CBaaS) Source</a>
<ul>
<li><a href="#orgheadline17">1.2.1. Distribution platform for AI/ML/CV algorithms</a></li>
<li><a href="#orgheadline20">1.2.2. Users</a></li>
</ul>
</li>
<li><a href="#orgheadline38">1.3. Unreal Learning Environment Source</a>
<ul>
<li><a href="#orgheadline26">1.3.1. Psychophysics</a></li>
<li><a href="#orgheadline30">1.3.2. Embodied AI</a></li>
<li><a href="#orgheadline37">1.3.3. Users/Collaborators</a></li>
</ul>
</li>
<li><a href="#orgheadline39">1.4. Collaboration Tracker</a></li>
</ul>
</li>
<li><a href="#orgheadline43">2. Maintenance</a>
<ul>
<li><a href="#orgheadline41">2.1. pipes-rt</a></li>
<li><a href="#orgheadline42">2.2. snap testsuite</a></li>
</ul>
</li>
<li><a href="#orgheadline44">3. Teaching</a></li>
<li><a href="#orgheadline45">4. Consults</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgheadline40" class="outline-2">
<h2 id="orgheadline40"><span class="section-number-2">1</span> Development</h2>
<div class="outline-text-2" id="text-1">
</div><div id="outline-container-orgheadline16" class="outline-3">
<h3 id="orgheadline16"><span class="section-number-3">1.1</span> Tagging</h3>
<div class="outline-text-3" id="text-1-1">
</div><div id="outline-container-orgheadline1" class="outline-4">
<h4 id="orgheadline1"><span class="section-number-4">1.1.1</span> Stimulus annotation platform</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
A unified platform for collecting stimulus tags from humans and algorithms. The tagging server keeps a database of stimulus sets and distributes them according to protocols defined by the researcher. Tagging clients are web pages (for human subjects), and an API accessible from several programming languages (for algorithmic subjects). Keeping a single platform for testing of humans and algorithms will make it easier to compare human and machine error patterns of mistakes, as we develop and assess AI systems that solve perception problems in human-like ways. Providing standard types for stimuli and responses will help different studies from different researchers contribute to a common pool of experimental data.
</p>
</div>
</div>
<div id="outline-container-orgheadline5" class="outline-4">
<h4 id="orgheadline5"><span class="section-number-4">1.1.2</span> Types of stimuli:</h4>
<div class="outline-text-4" id="text-1-1-2">
</div><ol class="org-ol"><li><a id="orgheadline2"></a>Images<br  /></li>
<li><a id="orgheadline3"></a>Movie clips<br  /></li>
<li><a id="orgheadline4"></a>Sounds<br  /></li></ol>
</div>
<div id="outline-container-orgheadline11" class="outline-4">
<h4 id="orgheadline11"><span class="section-number-4">1.1.3</span> Types of annotations:</h4>
<div class="outline-text-4" id="text-1-1-3">
</div><ol class="org-ol"><li><a id="orgheadline6"></a>Characters in clip<br  /></li>
<li><a id="orgheadline7"></a>Actions<br  /></li>
<li><a id="orgheadline8"></a>Low-level features (e.g. head direction)<br  /></li>
<li><a id="orgheadline9"></a>Speech transcripts<br  /></li>
<li><a id="orgheadline10"></a>Feelings about characters (good guy / bad guy)<br  /></li></ol>
</div>
<div id="outline-container-orgheadline15" class="outline-4">
<h4 id="orgheadline15"><span class="section-number-4">1.1.4</span> Users</h4>
<div class="outline-text-4" id="text-1-1-4">
</div><ol class="org-ol"><li><a id="orgheadline12"></a>Leyla Isik (Kanwisher, Poggio, Kreiman labs)<br  /></li>
<li><a id="orgheadline13"></a>Hanlin Tang (Kreiman lab)<br  /></li>
<li><a id="orgheadline14"></a>Andrei Barbu (Katz lab)<br  /></li></ol>
</div>
</div>
<div id="outline-container-orgheadline21" class="outline-3">
<h3 id="orgheadline21"><span class="section-number-3">1.2</span> Center for Brains, Minds and Machines as as Service (CBaaS) <a href="http://github.com/CBMM/CBaaS">Source</a></h3>
<div class="outline-text-3" id="text-1-2">
</div><div id="outline-container-orgheadline17" class="outline-4">
<h4 id="orgheadline17"><span class="section-number-4">1.2.1</span> Distribution platform for AI/ML/CV algorithms</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
We want AI, machine learning, and computer vision research results to be durable, composable and immediately usable. CBaaS provides a matching service to apply various algorithms (such as a pre-trained deep neural net image classifier) to new stimuli of the users' choosing (such as a new compound stimulus not in the original training set, or a scrambled image produced by genetic recombination specifically to try to fool the classifier). Recently-produced algorithms can participate in the site through a well-documented API in a work-stealing arrangement. More mature algorithms maybe coded to run directly on the server, or as javascript on the user's own machine. Algorithms requiring special hardware can process image data as CBasS clients indefinitely.
Another major goal of CBasS is the ability to introspect on algorithms, and to compose new ones from parts of old ones. For example, users may be interested in the activity levels of the 5th layer in a 6 layer image classifying net, or in retrieving the weights of one network to seed a new network that will will be trained on new images or with a different set of learning parameters.
</p>
</div>
</div>
<div id="outline-container-orgheadline20" class="outline-4">
<h4 id="orgheadline20"><span class="section-number-4">1.2.2</span> Users</h4>
<div class="outline-text-4" id="text-1-2-2">
</div><ol class="org-ol"><li><a id="orgheadline18"></a>CBCL, Poggio group<br  /></li>
<li><a id="orgheadline19"></a>Eithan Meyers, Hampshire College<br  /></li></ol>
</div>
</div>
<div id="outline-container-orgheadline38" class="outline-3">
<h3 id="orgheadline38"><span class="section-number-3">1.3</span> Unreal Learning Environment <a href="http://github.com/UnrealLearningEnvironment">Source</a></h3>
<div class="outline-text-3" id="text-1-3">
<p>
Using the Unreal game engine for running psychophysics tests and testing embodied AI simulations, similar to the EMPATH project.
</p>
</div>
<div id="outline-container-orgheadline26" class="outline-4">
<h4 id="orgheadline26"><span class="section-number-4">1.3.1</span> Psychophysics</h4>
<div class="outline-text-4" id="text-1-3-1">
</div><ol class="org-ol"><li><a id="orgheadline22"></a>Generate countless stmiuli (e.g. precarious block stackings for intuitive physics experiments)<br  /></li>
<li><a id="orgheadline23"></a>Demonstrate physical object interactions, allowing observers to build mental models of the objects (their relative weights, stickiness, attractive/repulsive forces)<br  /></li>
<li><a id="orgheadline24"></a>Run the simulation forward to provide feedback on predictions<br  /></li>
<li><a id="orgheadline25"></a>Model BCS building/Stata center for large-scale versions of Liz Spelke virtual/meat-space experiments<br  /></li></ol>
</div>
<div id="outline-container-orgheadline30" class="outline-4">
<h4 id="orgheadline30"><span class="section-number-4">1.3.2</span> Embodied AI</h4>
<div class="outline-text-4" id="text-1-3-2">
</div><ol class="org-ol"><li><a id="orgheadline27"></a>Place AI controlled avatars in the physical environment<br  /></li>
<li><a id="orgheadline28"></a>Run image classifiers on first-person views from the avatars. "naturalistic" stimuli<br  /></li>
<li><a id="orgheadline29"></a>Test alternative pose recognition algorithms, like those based on inferred pressure in the EMPATH model<br  /></li></ol>
</div>
<div id="outline-container-orgheadline37" class="outline-4">
<h4 id="orgheadline37"><span class="section-number-4">1.3.3</span> Users/Collaborators</h4>
<div class="outline-text-4" id="text-1-3-3">
</div><ol class="org-ol"><li><a id="orgheadline31"></a>Andrei Barbu<br  /></li>
<li><a id="orgheadline32"></a>Dan Yamins (DiCarlo lab)<br  /></li>
<li><a id="orgheadline33"></a>Tejas Kulkarni<br  /></li>
<li><a id="orgheadline34"></a>Tomer Ulman<br  /></li>
<li><a id="orgheadline35"></a>Zenna Tavares<br  /></li>
<li><a id="orgheadline36"></a>Will Whitney<br  /></li></ol>
</div>
</div>
<div id="outline-container-orgheadline39" class="outline-3">
<h3 id="orgheadline39"><span class="section-number-3">1.4</span> Collaboration Tracker</h3>
<div class="outline-text-3" id="text-1-4">
<p>
<a href="http://web.mit.edu/greghale/Public/collabplotb/collaborations.html">mockup</a> <a href="https://github.com/imalsogreg/collabplot">source</a>
</p>

<p>
A fun visualization of collaborations evolving through CBMM. Will allow selection of individual PIs and projects, with links to external sites. Projects with github pages will have some kind of dynamic indicator of how much recent activity has gone on in that project.
</p>
</div>
</div>
</div>
<div id="outline-container-orgheadline43" class="outline-2">
<h2 id="orgheadline43"><span class="section-number-2">2</span> Maintenance</h2>
<div class="outline-text-2" id="text-2">
</div><div id="outline-container-orgheadline41" class="outline-3">
<h3 id="orgheadline41"><span class="section-number-3">2.1</span> pipes-rt</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Real-time throttling for pipes coroutines, based on data timestamps or extrinsic timing signals
</p>
</div>
</div>
<div id="outline-container-orgheadline42" class="outline-3">
<h3 id="orgheadline42"><span class="section-number-3">2.2</span> snap testsuite</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Unit tests for the <a href="http://snapframework.com/">snap</a> web framework, which I use for all new projects
</p>
</div>
</div>
</div>
<div id="outline-container-orgheadline44" class="outline-2">
<h2 id="orgheadline44"><span class="section-number-2">3</span> Teaching</h2>
</div>
<div id="outline-container-orgheadline45" class="outline-2">
<h2 id="orgheadline45"><span class="section-number-2">4</span> Consults</h2>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Greg Hale</p>
<p class="date">Created: 2015-11-16 Mon 17:56</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
